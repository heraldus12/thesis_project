{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 1 (using 1 latent features):\n",
      "RMSE: 2.2395145912846335\n",
      "Adjusted R-squared: 0.6337600260092544\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 905us/step\n",
      "Iteration 2 (using 2 latent features):\n",
      "RMSE: 2.0393444014405686\n",
      "Adjusted R-squared: 0.6954028039969973\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 3 (using 3 latent features):\n",
      "RMSE: 1.2224937361533703\n",
      "Adjusted R-squared: 0.8902186265819485\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 4 (using 4 latent features):\n",
      "RMSE: 1.2383695969916597\n",
      "Adjusted R-squared: 0.8870124979402823\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 5 (using 5 latent features):\n",
      "RMSE: 1.3941550012545223\n",
      "Adjusted R-squared: 0.8563682978494614\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 6 (using 6 latent features):\n",
      "RMSE: 1.1208463590597013\n",
      "Adjusted R-squared: 0.9068843692840189\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 7 (using 7 latent features):\n",
      "RMSE: 1.2235837235964913\n",
      "Adjusted R-squared: 0.8886977481967464\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 8 (using 8 latent features):\n",
      "RMSE: 1.325837291969657\n",
      "Adjusted R-squared: 0.8689228111125635\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 9 (using 9 latent features):\n",
      "RMSE: 1.025123404099011\n",
      "Adjusted R-squared: 0.9214017258941358\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 10 (using 10 latent features):\n",
      "RMSE: 1.0284500772204577\n",
      "Adjusted R-squared: 0.9206503191564978\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 11 (using 11 latent features):\n",
      "RMSE: 0.8376277368456536\n",
      "Adjusted R-squared: 0.9472037704806496\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 12 (using 12 latent features):\n",
      "RMSE: 0.915193029963587\n",
      "Adjusted R-squared: 0.9367803179729098\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 13 (using 13 latent features):\n",
      "RMSE: 1.0061031689703457\n",
      "Adjusted R-squared: 0.9233623664804294\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 14 (using 14 latent features):\n",
      "RMSE: 1.0205133504239818\n",
      "Adjusted R-squared: 0.9209087076176776\n",
      "----------------------------------------\n",
      "22/22 [==============================] - 0s 1ms/step\n",
      "Iteration 15 (using 15 latent features):\n",
      "RMSE: 0.9705000682751983\n",
      "Adjusted R-squared: 0.9282501855406817\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Load and prepare the dataset\n",
    "df = pd.read_csv(\"soilmoisture_dataset.csv\", index_col=0)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "X = df.drop(['soil_temperature', 'datetime', 'soil_moisture'], axis=1)\n",
    "y = df['soil_moisture']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "# Define the autoencoder model\n",
    "def create_autoencoder(input_dim, encoding_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(encoding_dim, activation='leaky_relu', activity_regularizer=regularizers.l2(0.01))(input_layer)\n",
    "    decoded = Dense(input_dim, activation='linear')(encoded)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)  # Encoder model for dimensionality reduction\n",
    "    return autoencoder, encoder\n",
    "\n",
    "# Set the target number of features for dimensionality reduction\n",
    "# Perform PLS and model training in a loop\n",
    "for n_features in range(1, 16): \n",
    "    n_features = n_features  # Set desired number of reduced dimensions\n",
    "\n",
    "    # Build and compile the autoencoder\n",
    "    input_dim = X_standardized.shape[1]\n",
    "    autoencoder, encoder = create_autoencoder(input_dim, n_features)\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(X_standardized, X_standardized, epochs=100, batch_size=32, shuffle=True, validation_split=0.3, verbose=0)\n",
    "\n",
    "    # Use the encoder to transform data to lower-dimensional space\n",
    "    X_reduced = encoder.predict(X_standardized)\n",
    "\n",
    "    # Convert reduced features to DataFrame\n",
    "    df_reduced = pd.DataFrame(X_reduced, columns=[f'feature_{i+1}' for i in range(n_features)])\n",
    "\n",
    "    # Split data for regression\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_reduced, y, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Train regression model on reduced features\n",
    "    model = SVR(kernel='rbf', C=1000, gamma='scale')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE and Adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    def adjusted_r2_score(y_true, y_pred, n_features):\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        n = len(y_true)\n",
    "        adj_r2 = 1 - (1 - r2) * (n - 1) / (n - n_features - 1)\n",
    "        return adj_r2\n",
    "\n",
    "    adj_r2 = adjusted_r2_score(y_test, y_pred, n_features)\n",
    "\n",
    "    print(f\"Iteration {n_features} (using {n_features} latent features):\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"Adjusted R-squared: {adj_r2}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Model Summary:\n",
      "Model: \"model_516\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_259 (InputLayer)      [(None, 125)]             0         \n",
      "                                                                 \n",
      " dense_524 (Dense)           (None, 15)                1890      \n",
      "                                                                 \n",
      " dense_525 (Dense)           (None, 125)               2000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,890\n",
      "Trainable params: 3,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of the autoencoder architecture\n",
    "print(\"Autoencoder Model Summary:\")\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# Define the dimensionality of the input and the compressed representation\n",
    "input_dim = 125  # e.g., for a 28x28 image flattened to a vector\n",
    "encoding_dim = 15  # target dimensionality for reduced data\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(128, activation='relu')(input_layer)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded_output = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder (to reconstruct the original input)\n",
    "decoded = Dense(64, activation='relu')(encoded_output)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded_output = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Combine Encoder and Decoder into an Autoencoder Model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded_output)\n",
    "\n",
    "# Separate Encoder Model (for dimensionality reduction)\n",
    "encoder = Model(inputs=input_layer, outputs=encoded_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fit the model to the data\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_test, X_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
